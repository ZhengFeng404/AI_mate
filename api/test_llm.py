# test_llm_performance.py
import asyncio
from llm_handler import get_gemini_response_with_history
import time
import base64


async def test_scenario(scenario_name, user_input, image_base64=None):
    print(f"\nğŸš€ æµ‹è¯•åœºæ™¯: {scenario_name}")
    print(f"è¾“å…¥å†…å®¹: {user_input[:50]}...")

    # æ¨¡æ‹Ÿå†å²è®°å½•
    manual_history = [
        {"user_text": "ä½ å¥½", "ai_response": "ä½ å¥½ï¼æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿ"},
        {"user_text": "è¿˜ä¸é”™ï¼Œä½ å‘¢ï¼Ÿ", "ai_response": "æˆ‘ä¹Ÿå¾ˆå¥½ï¼Œè°¢è°¢å…³å¿ƒï¼"}
    ]

    # è¿è¡Œæµ‹è¯•
    start_time = time.time()
    response = []
    async for chunk in get_gemini_response_with_history(
            user_input=user_input,
            user_id="test_user",
            manual_history=manual_history,
            image_base64=image_base64
    ):
        if chunk["type"] == "segment":
            response.append(chunk["segment"])
            break  # ä»…æ•è·é¦–segment

    print(f"é¦–segmentå†…å®¹: {''.join(response)}")
    print(f"æ€»æµ‹è¯•æ—¶é—´: {time.time() - start_time:.4f}s")


if __name__ == "__main__":


    # åœºæ™¯2ï¼šéœ€è¦è§†è§‰å“åº”çš„è¯¢é—®
    with open("test_image.jpg", "rb") as f:
        test_image = base64.b64encode(f.read()).decode()

    asyncio.run(test_scenario(
        "è§†è§‰ç›¸å…³è¯¢é—®",
        "ä½ èƒ½çœ‹åˆ°æˆ‘ç°åœ¨æ‹¿ç€ä»€ä¹ˆå—ï¼Ÿ",
        image_base64=test_image
    ))